\section{Introduction}
\label{sec:introduction}

Multi-objective evolutionary algorithms (MOEAs) have become indispensable tools for solving complex real-world optimisation problems where multiple conflicting objectives must be optimised simultaneously~\cite{coello2007survey}. Among MOEAs, NSGA-II~\cite{deb2002fast} remains the most widely used algorithm, featuring elitist non-dominated sorting as its core selection mechanism. The algorithm assigns each solution in the population to a Pareto front (rank), enabling selection pressure toward the true Pareto-optimal set while maintaining diversity.

Non-dominated sorting is the dominant computational bottleneck in NSGA-II and its successors. The fast non-dominated sort proposed by Deb et al.~\cite{deb2002fast} requires $\mathcal{O}(MN^2)$ comparisons for a population of $N$ solutions with $M$ objectives. While this is efficient for small populations, modern applications in engineering design, machine learning hyperparameter tuning, and many-objective optimisation demand populations of $N = 10{,}000$ or more with $M \geq 5$ objectives, making non-dominated sorting prohibitively slow. Divide-and-conquer approaches such as DCNS~\cite{mishra2016dcns,mishra2019dcns_journal} reduce the best-case complexity to $\mathcal{O}(N \log N + MN)$, but even these sequential implementations struggle at scale.

Graphics Processing Units (GPUs) offer massive parallelism with thousands of cores capable of executing data-parallel operations simultaneously~\cite{nvidia2023cuda}. While theoretical parallel analyses of non-dominated sorting exist---notably the P-ENS approach by Mishra and Coello~\cite{mishra2018pens}, which provides PRAM-CREW complexity bounds---no practical, fully GPU-native implementation has been demonstrated. The gap between theoretical parallel algorithms and real GPU implementations is significant: PRAM models ignore memory hierarchy, thread divergence, and the architectural constraints of modern GPUs.

This paper makes concrete progress toward bridging that gap with the following contributions:
\begin{enumerate}
    \item \textbf{GPU-NDS:} a GPU-accelerated non-dominated sorting algorithm that adapts two key insights from DCNS~\cite{mishra2016dcns,mishra2019dcns_journal} and Prakash et al.~\cite{prakash2024sumobj} --- sum-of-objectives pre-sorting and comparison pruning --- to the GPU memory hierarchy via tiled shared-memory dominance checks. We prove a factor-$T$ reduction in global memory traffic (Proposition~3) and validate 30--60\% comparison reduction empirically. GPU-NDS produces provably identical front assignments to sequential non-dominated sorting (Proposition~2).
    \item \textbf{Sum-of-objectives pre-sort} integrated as a GPU-friendly coalescing mechanism that prunes unnecessary dominance comparisons by establishing an ordering bound.
    \item \textbf{An analytical performance model} for comparison count and memory transactions, validated empirically across benchmark problems.
    \item \textbf{Comprehensive benchmarks} on the DTLZ~\cite{deb2005dtlz} benchmark suite showing significant speedups over CPU-DCNS, CPU-NSGA2, and CPU-BOS baselines, with the GPU advantage increasing for larger $N$ and $M$.
    \item \textit{Reproducible evaluation methodology}: we demonstrate that comparing GPU algorithms against Python baselines inflates reported speedups by up to three orders of magnitude ($8{,}173\times$ vs.\ $12.5\times$ at $N\!=\!5{,}000$), and advocate for compiled-language baselines as standard practice in GPU algorithm evaluation.
\end{enumerate}
